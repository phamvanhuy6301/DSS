{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.20.0)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->tensorflow_addons) (3.0.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_addons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.10.0 and strictly below 2.13.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.9.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Có những người bước đến, họ lấp đầy hạnh phúc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Thấy nhiều bạn chê tiki gói hàng quá, may sao ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Bìa cực xinh, tiki giao hàng nhanh, sách không...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Sách lúc nhận hình thức rất ổn, không cong vên...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Một cuốn sách rất đáng đọc về tình yêu thương ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                            content\n",
       "0       5  Có những người bước đến, họ lấp đầy hạnh phúc ...\n",
       "1       5  Thấy nhiều bạn chê tiki gói hàng quá, may sao ...\n",
       "2       5  Bìa cực xinh, tiki giao hàng nhanh, sách không...\n",
       "3       5  Sách lúc nhận hình thức rất ổn, không cong vên...\n",
       "4       5  Một cuốn sách rất đáng đọc về tình yêu thương ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/ADMIN/OneDrive - Hanoi University of Science and Technology/2022-2/Hệ hỗ trợ quyết định/archive/comments.csv',\n",
    "                 usecols = ['rating', 'content'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of train dataset: 141281\n"
     ]
    }
   ],
   "source": [
    "print(f'Len of train dataset: {len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='rating', ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = df.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating         0\n",
       "content    38018\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103263, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 1\n"
     ]
    }
   ],
   "source": [
    "X = df.content.copy()\n",
    "y = df.rating.copy()\n",
    "y = tf.keras.utils.to_categorical(y)\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    \n",
    "    strategy = tf.distribute.experimental.TPUStrategy\n",
    "except ValueError:\n",
    "    strategy = tf.distribute.get_strategy() \n",
    "    print('Number of replicas:', strategy.num_replicas_in_sync) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CPU\n",
      "Number of accelerators:  1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "    gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "    \n",
    "if tpu:\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu,) \n",
    "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "elif len(gpus) > 1:\n",
    "    strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
    "    print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
    "elif len(gpus) == 1:\n",
    "    strategy = tf.distribute.get_strategy() \n",
    "    print('Running on single GPU ', gpus[0].name)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() \n",
    "    print('Running on CPU')\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 22.3 kB/s eta 0:00:00\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.3.23-cp310-cp310-win_amd64.whl (267 kB)\n",
      "     ------------------------------------- 267.9/267.9 kB 15.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 22.9 kB/s eta 0:00:00\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "     ------------------------------------- 151.7/151.7 kB 20.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "     ------------------------------------- 200.1/200.1 kB 13.3 kB/s eta 0:00:00\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "     --------------------------------------- 77.1/77.1 kB 23.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Installing collected packages: tokenizers, tqdm, regex, pyyaml, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.4 pyyaml-6.0 regex-2023.3.23 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.28.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 21.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.1)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 24.3 kB/s eta 0:00:00\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Using cached huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.7.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2023.3.23-cp310-cp310-win_amd64.whl (267 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Installing collected packages: tokenizers, tqdm, regex, pyyaml, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.4 pyyaml-6.0 regex-2023.3.23 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.28.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f2588b63d242d5bfca50f4fceda59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ADMIN\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647fa7816dae4eeeb0cb66935e4f182c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e16d81e49b34fa78350067a3290da22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "MAX_LEN = 200\n",
    "model_name = 'vinai/phobert-base'\n",
    "\n",
    "# Tokenizing\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "inputs = [tokenizer(item,\n",
    "                    max_length = MAX_LEN,\n",
    "                    padding = 'max_length', \n",
    "                    truncation = True, \n",
    "                    return_tensors = 'np')['input_ids'].reshape(MAX_LEN)\n",
    "          for _, item in X.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(inputs), \n",
    "                                                    y,\n",
    "                                                    random_state=1905, \n",
    "                                                    test_size=0.2, \n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Bidirectional, LSTM, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154eb34221964b429e3ed399c77cac3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/740M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at vinai/phobert-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at vinai/phobert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "with strategy.scope():\n",
    "    encoder = TFAutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    input_ids = Input(shape=(MAX_LEN,), dtype=tf.int32)\n",
    "    \n",
    "    embedding = encoder(input_ids)[1]\n",
    "\n",
    "    x = Dense(128, activation = 'relu', kernel_regularizer = regularizers.L2(0.1))(embedding)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(y.shape[1], \n",
    "              activation = 'softmax',\n",
    "              kernel_initializer=tf.initializers.GlorotUniform(seed=1905),\n",
    "              name='output_layer')(x)\n",
    "    \n",
    "    model = Model(inputs=[input_ids], outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 200)]             0         \n",
      "                                                                 \n",
      " tf_roberta_model (TFRoberta  TFBaseModelOutputWithPoo  134998272\n",
      " Model)                      lingAndCrossAttentions(l            \n",
      "                             ast_hidden_state=(None,             \n",
      "                             200, 768),                          \n",
      "                              pooler_output=(None, 76            \n",
      "                             8),                                 \n",
      "                              past_key_values=None, h            \n",
      "                             idden_states=None, atten            \n",
      "                             tions=None, cross_attent            \n",
      "                             ions=None)                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               98432     \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 135,097,478\n",
      "Trainable params: 135,097,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = tf.Variable(0, trainable=False)\n",
    "schedule = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    [10000, 15000], [1e-3, 1e-4, 1e-5])\n",
    "\n",
    "lr = 1e-2 * schedule(step)\n",
    "wd = lambda: 1e-5 * schedule(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tfa.optimizers.AdamW(weight_decay=wd,\n",
    "                                   learning_rate=lr),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train,\n",
    "                    y_train, \n",
    "                    epochs = 20,\n",
    "                    verbose = 1, \n",
    "                    validation_split = 0.1,\n",
    "                    batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "acc = history.history['accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, acc, 'b', label = 'Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label = 'Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, loss, 'b', label = 'Trainig loss')\n",
    "plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
